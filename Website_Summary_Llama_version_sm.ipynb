{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8de26834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write down your website URL here: \n",
      "https://www.nlab-utsw.org\n",
      "**Summary of N-LAB Website**\n",
      "==========================\n",
      "\n",
      "The N-LAB website is dedicated to developing novel neuroimaging and neuroengineering methods to integrate molecular and system neuroscience. The lab aims to understand the neural mechanisms of reward, learning, and memory in rodents' brains.\n",
      "\n",
      "**Key Information**\n",
      "-------------------\n",
      "\n",
      "* The N-LAB's mission is to develop innovative approaches for brain science research.\n",
      "* They are located at UT Southwestern Medical Center and have access to state-of-the-art imaging resources.\n",
      "* The lab has strong support from the Advanced Imaging Research Center (AIRC) and can utilize various core facilities on campus.\n",
      "\n",
      "**News/Announcements**\n",
      "----------------------\n",
      "\n",
      "None found. However, the website appears to be using Google Sites, which may indicate that updates or announcements are being made through this platform.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Constants\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\"\n",
    "\n",
    "# Headers for website requests\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Referer\": \"https://www.google.com/\",  # Appears as if you're coming from Google\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"DNT\": \"1\",  # Do Not Track request\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "    \"Sec-Fetch-Dest\": \"document\",\n",
    "    \"Sec-Fetch-Mode\": \"navigate\",\n",
    "    \"Sec-Fetch-Site\": \"same-origin\",\n",
    "    \"Sec-Fetch-User\": \"?1\",\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Initialize the website object and fetch content.\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()  # Raise an error for bad responses\n",
    "        except requests.RequestException as e:\n",
    "            print(f'Failed to fetch website: {e}')\n",
    "            self.title = 'Error fetching website'\n",
    "            self.text = ''\n",
    "            return\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        \n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = 'No readable content found'\n",
    "\n",
    "url = input('Write down your website URL here: \\n')\n",
    "website = Website(url)\n",
    "\n",
    "# Step 1: Create prompts\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an senior research scientist that analyzes the contents of a website \\\n",
    "    and provides a short summary, ignoring text that might be navigation related. \\\n",
    "    Respond in markdown.\"\n",
    ")\n",
    "user_prompt = (\n",
    "    f\"You are looking at a website titled {website.title}. \\n\\\n",
    "    The contents of this website is as follows; \\\n",
    "    please provide a short summary of this website in markdown. \\\n",
    "    If it includes news or announcements, then summarize these too.\\n\\n\\\n",
    "    {website.text}\"\n",
    ")\n",
    "\n",
    "# Step 2: Construct messages list\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "\n",
    "# Step3: Prepare API Request Payload\n",
    "payload = {\n",
    "    'model': MODEL,\n",
    "    'messages': messages,\n",
    "    'stream': False\n",
    "}\n",
    "\n",
    "# Step 4: Call Llama 3.2 and Handle Response\n",
    "try:\n",
    "    response = requests.post(OLLAMA_API, \n",
    "                             json=payload, \n",
    "                             headers=HEADERS)\n",
    "    result = response.json().get('message', {}).get('content', 'No response received.')\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f'Llama API call failed: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c871fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
